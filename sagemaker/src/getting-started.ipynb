{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Create a Jupyter Notebook and Initialize Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role: arn:aws:iam::191216456264:role/service-role/AmazonSageMaker-ExecutionRole-20181030T052942\n",
      "bucket: rh-sagemaker-20181024\n"
     ]
    }
   ],
   "source": [
    "## 3.1\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# retrieve the name of the IAM role that the notebook is running under\n",
    "role = get_execution_role()\n",
    "bucket = 'rh-sagemaker-20181024'\n",
    "\n",
    "print(\"role: {}\".format(role))\n",
    "print(\"bucket: {}\".format(bucket))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Download, Explore, and Transform the Training Data\n",
    "\n",
    "* Download MNIST dataset\n",
    "* Transform from `numpy.array` to `RecordIO` format\n",
    "    * [RecordIO Data Format](http://mxnet.incubator.apache.org/architecture/note_data_loading.html#data-format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Download MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.2.1\n",
    "import pickle, gzip, numpy, urllib.request, json\n",
    "\n",
    "# download the dataset to the notebook's local storage\n",
    "urllib.request.urlretrieve(\"http://deeplearning.net/data/mnist/mnist.pkl.gz\", \"mnist.pkl.gz\")\n",
    "\n",
    "# deserialize the contents into train, validation, and test sets\n",
    "with gzip.open('mnist.pkl.gz', 'rb') as f:\n",
    "    train_set, valid_set, test_set = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Explore the Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 3.2.2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (2,10)\n",
    "\n",
    "def show_digit(img, caption='', subplot=None):\n",
    "    if subplot == None:\n",
    "        _, (subplot) = plt.subplots(1,1)\n",
    "    imgr = img.reshape((28,28))\n",
    "    subplot.axis('off')\n",
    "    subplot.imshow(imgr, cmap='gray')\n",
    "    plt.title(caption)\n",
    "\n",
    "show_digit(train_set[0][30], 'This is a {}'.format(train_set[1][30]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Transform the Training Dataset and Upload to S3\n",
    "\n",
    "* transform from numpy.array to RecordIO protobuf format\n",
    "* more efficient for the algorithms provided by SageMaker\n",
    "* 2 approaches available:\n",
    "  * high-level SageMaker Python libraries\n",
    "  * lower level boto3 Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.2.3 -- LOW LEVEL handling\n",
    "from sagemaker.amazon.common import write_numpy_to_dense_tensor\n",
    "import io\n",
    "import boto3\n",
    "\n",
    "def save_numpy_as_dense_tensor(train_set, bucket, data_key):\n",
    "    ## convert the training data into the format required by the\n",
    "    ## SageMaker K-Means algorithm\n",
    "    buf = io.BytesIO()\n",
    "    write_numpy_to_dense_tensor(buf, train_set[0], train_set[1])\n",
    "    buf.seek(0)\n",
    "\n",
    "    boto3.resource('s3').Bucket(bucket).Object(data_key).upload_fileobj(buf)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data will be uploaded to: s3://rh-sagemaker-20181024/kmeans_lowlevel_example/data\n",
      "CPU times: user 8.57 s, sys: 252 ms, total: 8.82 s\n",
      "Wall time: 9.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data_key = 'kmeans_lowlevel_example/data'\n",
    "data_location = 's3://{}/{}'.format(bucket, data_key)\n",
    "\n",
    "print('training data will be uploaded to: {}'.format(data_location))\n",
    "\n",
    "save_numpy_as_dense_tensor(train_set, bucket, data_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Train a Model\n",
    "\n",
    "* Call `CreateTrainingJob`, providing\n",
    "  * training image ECR path\n",
    "  * training data S3 path\n",
    "  * resources configuration to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Choose the Training Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Create a Training Job\n",
    "\n",
    "* high-level Python api\n",
    "    * create instance of training algorithm\n",
    "    * call `fit` method, passing configuration details\n",
    "    \n",
    "    \n",
    "* role: name of the IAM role under which SageMaker runs while performing training\n",
    "* output_path: S3 location for storing generated output artifacts\n",
    "* train_instance_count: # of instances to use for training\n",
    "* train_instance_type: type of instances to use for training\n",
    "* k: the number of clusters to create\n",
    "* data_location: location of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data will be uploaded to: s3://rh-sagemaker-20181024/kmeans_highlevel_example/data\n",
      "training artifacts will be uploaded to: s3://rh-sagemaker-20181024/kmeans_highlevel_example/output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: kmeans-2018-10-30-11-08-55-639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-30 11:08:55 Starting - Starting the training job...\n",
      "2018-10-30 11:08:56 Starting - Launching requested ML instances.........\n",
      "2018-10-30 11:10:29 Starting - Preparing the instances for training......\n",
      "2018-10-30 11:11:41 Downloading - Downloading input data...\n",
      "2018-10-30 11:12:22 Training - Training image download completed. Training in progress.\n",
      "2018-10-30 11:12:22 Uploading - Uploading generated training model\n",
      "\u001b[32mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:17 INFO 140408755816256] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'true', u'epochs': u'1', u'init_method': u'random', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:17 INFO 140408755816256] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'784', u'k': u'10', u'force_dense': u'True'}\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:17 INFO 140408755816256] Final configuration: {u'k': u'10', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'init_method': u'random', u'feature_dim': u'784', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:17 WARNING 140408755816256] Loggers have already been setup.\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:17 INFO 140408755816256] Environment: {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/dffe4fd2-da66-47d1-a368-f8baa1d6ddda', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_WORKER': '2', 'SAGEMAKER_HTTP_PORT': '8080', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'ethwe', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.32.0.4', 'AWS_REGION': 'us-east-1', 'NVIDIA_VISIBLE_DEVICES': 'all', 'TRAINING_JOB_NAME': 'kmeans-2018-10-30-11-08-55-639', 'HOME': '/root', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '18', 'HOSTNAME': 'aws', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/661187c4-ad3c-4b0d-9b5e-6dcfa894459d', 'DMLC_ROLE': 'worker', 'PWD': '/', 'DMLC_NUM_SERVER': '1'}\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:17 INFO 140408755816256] Using default worker.\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:17 INFO 140408755816256] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:17 INFO 140408755816256] Create Store: dist_async\u001b[0m\n",
      "\u001b[31mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:17 INFO 140152484075328] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'true', u'epochs': u'1', u'init_method': u'random', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:17 INFO 140152484075328] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'784', u'k': u'10', u'force_dense': u'True'}\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:17 INFO 140152484075328] Final configuration: {u'k': u'10', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'init_method': u'random', u'feature_dim': u'784', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:17 WARNING 140152484075328] Loggers have already been setup.\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:17 INFO 140152484075328] Launching parameter server for role scheduler\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:17 INFO 140152484075328] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/160d7242-857c-43c8-9e87-3611eaca8873', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'ethwe', 'SHLVL': '1', 'AWS_REGION': 'us-east-1', 'NVIDIA_VISIBLE_DEVICES': 'all', 'TRAINING_JOB_NAME': 'kmeans-2018-10-30-11-08-55-639', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '18', 'HOSTNAME': 'aws', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/4e47f2b1-0f4f-4fb3-a029-b899986914d9', 'PWD': '/'}\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:17 INFO 140152484075328] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/160d7242-857c-43c8-9e87-3611eaca8873', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '2', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'ethwe', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.32.0.4', 'AWS_REGION': 'us-east-1', 'NVIDIA_VISIBLE_DEVICES': 'all', 'TRAINING_JOB_NAME': 'kmeans-2018-10-30-11-08-55-639', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '18', 'HOSTNAME': 'aws', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/4e47f2b1-0f4f-4fb3-a029-b899986914d9', 'DMLC_ROLE': 'scheduler', 'PWD': '/', 'DMLC_NUM_SERVER': '1'}\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:17 INFO 140152484075328] Launching parameter server for role server\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:17 INFO 140152484075328] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/160d7242-857c-43c8-9e87-3611eaca8873', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'ethwe', 'SHLVL': '1', 'AWS_REGION': 'us-east-1', 'NVIDIA_VISIBLE_DEVICES': 'all', 'TRAINING_JOB_NAME': 'kmeans-2018-10-30-11-08-55-639', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '18', 'HOSTNAME': 'aws', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/4e47f2b1-0f4f-4fb3-a029-b899986914d9', 'PWD': '/'}\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:17 INFO 140152484075328] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/160d7242-857c-43c8-9e87-3611eaca8873', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '2', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'ethwe', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.32.0.4', 'AWS_REGION': 'us-east-1', 'NVIDIA_VISIBLE_DEVICES': 'all', 'TRAINING_JOB_NAME': 'kmeans-2018-10-30-11-08-55-639', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '18', 'HOSTNAME': 'aws', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/4e47f2b1-0f4f-4fb3-a029-b899986914d9', 'DMLC_ROLE': 'server', 'PWD': '/', 'DMLC_NUM_SERVER': '1'}\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:17 INFO 140152484075328] Environment: {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/160d7242-857c-43c8-9e87-3611eaca8873', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_WORKER': '2', 'SAGEMAKER_HTTP_PORT': '8080', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'ethwe', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.32.0.4', 'AWS_REGION': 'us-east-1', 'NVIDIA_VISIBLE_DEVICES': 'all', 'TRAINING_JOB_NAME': 'kmeans-2018-10-30-11-08-55-639', 'HOME': '/root', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '18', 'HOSTNAME': 'aws', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/4e47f2b1-0f4f-4fb3-a029-b899986914d9', 'DMLC_ROLE': 'worker', 'PWD': '/', 'DMLC_NUM_SERVER': '1'}\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:17 INFO 140152484075328] Using default worker.\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:17 INFO 140152484075328] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:17 INFO 140152484075328] Create Store: dist_async\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:18 INFO 140408755816256] nvidia-smi took: 0.0251770019531 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:18 INFO 140408755816256] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:18 INFO 140408755816256] Setting up with params: {u'k': u'10', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'init_method': u'random', u'feature_dim': u'784', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[32m/opt/amazon/lib/python2.7/site-packages/ai_algorithms_sdk/config/config_helper.py:172: DeprecationWarning: deprecated\n",
      "  warnings.warn(\"deprecated\", DeprecationWarning)\u001b[0m\n",
      "\u001b[32m/opt/amazon/lib/python2.7/site-packages/ai_algorithms_sdk/config/config_helper.py:122: DeprecationWarning: deprecated\n",
      "  warnings.warn(\"deprecated\", DeprecationWarning)\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:18 INFO 140408755816256] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:18 INFO 140408755816256] number of center slices 1\u001b[0m\n",
      "\u001b[32m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1540897938.62683, \"Dimensions\": {\"Host\": \"algo-2\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1540897938.626798}\n",
      "\u001b[0m\n",
      "\u001b[32m[2018-10-30 11:12:18.647] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 63, \"num_examples\": 1}\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:18 INFO 140408755816256] processed a total of 25000 examples\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:18 INFO 140408755816256] #progress_metric: host=algo-2, completed 100 % of epochs\u001b[0m\n",
      "\u001b[32m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 25000, \"sum\": 25000.0, \"min\": 25000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}, \"Total Records Seen\": {\"count\": 1, \"max\": 30000, \"sum\": 30000.0, \"min\": 30000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 25000, \"sum\": 25000.0, \"min\": 25000}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1540897938.876442, \"Dimensions\": {\"Host\": \"algo-2\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\", \"epoch\": 0}, \"StartTime\": 1540897938.647415}\n",
      "\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:18 INFO 140408755816256] #throughput_metric: host=algo-2, train throughput=109091.66573 records/second\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:18 INFO 140408755816256] shrinking 100 centers into 10\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:18 INFO 140152484075328] nvidia-smi took: 0.0251898765564 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:18 INFO 140152484075328] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:18 INFO 140152484075328] Setting up with params: {u'k': u'10', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'init_method': u'random', u'feature_dim': u'784', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[31m/opt/amazon/lib/python2.7/site-packages/ai_algorithms_sdk/config/config_helper.py:172: DeprecationWarning: deprecated\n",
      "  warnings.warn(\"deprecated\", DeprecationWarning)\u001b[0m\n",
      "\u001b[31m/opt/amazon/lib/python2.7/site-packages/ai_algorithms_sdk/config/config_helper.py:122: DeprecationWarning: deprecated\n",
      "  warnings.warn(\"deprecated\", DeprecationWarning)\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:18 INFO 140152484075328] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:18 INFO 140152484075328] number of center slices 1\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1540897938.627097, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1540897938.627066}\n",
      "\u001b[0m\n",
      "\u001b[31m[2018-10-30 11:12:18.643] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 59, \"num_examples\": 1}\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:18 INFO 140152484075328] processed a total of 25000 examples\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:18 INFO 140152484075328] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 25000, \"sum\": 25000.0, \"min\": 25000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}, \"Total Records Seen\": {\"count\": 1, \"max\": 30000, \"sum\": 30000.0, \"min\": 30000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 25000, \"sum\": 25000.0, \"min\": 25000}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1540897938.860251, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\", \"epoch\": 0}, \"StartTime\": 1540897938.643109}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:18 INFO 140152484075328] #throughput_metric: host=algo-1, train throughput=114926.166523 records/second\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:18 INFO 140152484075328] shrinking 100 centers into 10\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:18 INFO 140152484075328] local kmeans attempt #0. Current mean square distance 11.323638\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:18 INFO 140152484075328] local kmeans attempt #1. Current mean square distance 11.467669\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:19 INFO 140152484075328] local kmeans attempt #2. Current mean square distance 11.549876\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:19 INFO 140152484075328] local kmeans attempt #3. Current mean square distance 11.293810\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:19 INFO 140152484075328] local kmeans attempt #4. Current mean square distance 11.496387\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:19 INFO 140152484075328] local kmeans attempt #5. Current mean square distance 11.753560\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:19 INFO 140152484075328] local kmeans attempt #6. Current mean square distance 10.850412\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:19 INFO 140152484075328] local kmeans attempt #7. Current mean square distance 11.421850\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:19 INFO 140152484075328] local kmeans attempt #8. Current mean square distance 11.512566\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:19 INFO 140152484075328] local kmeans attempt #9. Current mean square distance 11.016404\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:19 INFO 140152484075328] finished shrinking process. Mean Square Distance = 11\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:19 INFO 140152484075328] #quality_metric: host=algo-1, train msd <loss>=10.8504123688\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:19 INFO 140152484075328] batch data loading with context took: 24.2865%, (0.053462 secs)\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:19 INFO 140152484075328] compute all data-center distances: point norm took: 21.9184%, (0.048249 secs)\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:19 INFO 140152484075328] compute all data-center distances: inner product took: 19.7148%, (0.043398 secs)\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:19 INFO 140152484075328] predict compute msd took: 13.3445%, (0.029375 secs)\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:19 INFO 140152484075328] gradient: cluster center took: 8.8411%, (0.019462 secs)\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:19 INFO 140152484075328] collect from kv store took: 4.3482%, (0.009572 secs)\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:19 INFO 140152484075328] splitting centers key-value pair took: 2.7461%, (0.006045 secs)\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:19 INFO 140152484075328] gradient: one_hot took: 1.6572%, (0.003648 secs)\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:19 INFO 140152484075328] gradient: cluster size  took: 1.6527%, (0.003638 secs)\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:19 INFO 140152484075328] compute all data-center distances: center norm took: 0.7329%, (0.001613 secs)\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:19 INFO 140152484075328] update state and report convergance took: 0.6072%, (0.001337 secs)\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:19 INFO 140152484075328] update set-up time took: 0.0950%, (0.000209 secs)\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:19 INFO 140152484075328] predict minus dist took: 0.0553%, (0.000122 secs)\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:19 INFO 140152484075328] TOTAL took: 0.220130205154\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:19 INFO 140152484075328] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 314.3751621246338, \"sum\": 314.3751621246338, \"min\": 314.3751621246338}, \"initialize.time\": {\"count\": 1, \"max\": 22.422075271606445, \"sum\": 22.422075271606445, \"min\": 22.422075271606445}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.19502639770507812, \"sum\": 0.19502639770507812, \"min\": 0.19502639770507812}, \"update.time\": {\"count\": 1, \"max\": 216.68386459350586, \"sum\": 216.68386459350586, \"min\": 216.68386459350586}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"state.serialize.time\": {\"count\": 1, \"max\": 0.5459785461425781, \"sum\": 0.5459785461425781, \"min\": 0.5459785461425781}, \"_shrink.time\": {\"count\": 1, \"max\": 312.4868869781494, \"sum\": 312.4868869781494, \"min\": 312.4868869781494}}, \"EndTime\": 1540897939.192965, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1540897938.581927}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/30/2018 11:12:19 INFO 140152484075328] Test data is not provided.\u001b[0m\n",
      "\u001b[31m[2018-10-30 11:12:19.193] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 2, \"duration\": 549, \"num_examples\": 5}\u001b[0m\n",
      "\u001b[31m[2018-10-30 11:12:19.193] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"duration\": 608, \"num_epochs\": 2, \"num_examples\": 6}\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 1887.8929615020752, \"sum\": 1887.8929615020752, \"min\": 1887.8929615020752}, \"setuptime\": {\"count\": 1, \"max\": 28.237104415893555, \"sum\": 28.237104415893555, \"min\": 28.237104415893555}}, \"EndTime\": 1540897939.196664, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1540897939.193051}\n",
      "\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:18 INFO 140408755816256] local kmeans attempt #0. Current mean square distance 11.408212\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:18 INFO 140408755816256] local kmeans attempt #1. Current mean square distance 11.302434\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:18 INFO 140408755816256] local kmeans attempt #2. Current mean square distance 11.549876\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:19 INFO 140408755816256] local kmeans attempt #3. Current mean square distance 11.422704\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:19 INFO 140408755816256] local kmeans attempt #4. Current mean square distance 11.427080\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:19 INFO 140408755816256] local kmeans attempt #5. Current mean square distance 11.251129\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:19 INFO 140408755816256] local kmeans attempt #6. Current mean square distance 10.850412\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:19 INFO 140408755816256] local kmeans attempt #7. Current mean square distance 11.280325\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:19 INFO 140408755816256] local kmeans attempt #8. Current mean square distance 11.682590\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:19 INFO 140408755816256] local kmeans attempt #9. Current mean square distance 11.337234\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:19 INFO 140408755816256] finished shrinking process. Mean Square Distance = 11\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:19 INFO 140408755816256] #quality_metric: host=algo-2, train msd <loss>=10.8504123688\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:19 INFO 140408755816256] compute all data-center distances: inner product took: 35.3013%, (0.081666 secs)\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:19 INFO 140408755816256] batch data loading with context took: 17.9424%, (0.041508 secs)\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:19 INFO 140408755816256] compute all data-center distances: point norm took: 15.0840%, (0.034895 secs)\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:19 INFO 140408755816256] predict compute msd took: 12.4928%, (0.028901 secs)\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:19 INFO 140408755816256] collect from kv store took: 6.5059%, (0.015051 secs)\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:19 INFO 140408755816256] gradient: cluster center took: 6.4675%, (0.014962 secs)\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:19 INFO 140408755816256] splitting centers key-value pair took: 1.9755%, (0.004570 secs)\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:19 INFO 140408755816256] gradient: one_hot took: 1.5056%, (0.003483 secs)\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:19 INFO 140408755816256] gradient: cluster size  took: 1.3408%, (0.003102 secs)\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:19 INFO 140408755816256] compute all data-center distances: center norm took: 0.6290%, (0.001455 secs)\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:19 INFO 140408755816256] update state and report convergance took: 0.5940%, (0.001374 secs)\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:19 INFO 140408755816256] update set-up time took: 0.0995%, (0.000230 secs)\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:19 INFO 140408755816256] predict minus dist took: 0.0617%, (0.000143 secs)\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:19 INFO 140408755816256] TOTAL took: 0.231339931488\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:19 INFO 140408755816256] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:19 INFO 140408755816256] No model is serialized on a non-master node\u001b[0m\n",
      "\u001b[32m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 340.6038284301758, \"sum\": 340.6038284301758, \"min\": 340.6038284301758}, \"initialize.time\": {\"count\": 1, \"max\": 21.129846572875977, \"sum\": 21.129846572875977, \"min\": 21.129846572875977}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.07700920104980469, \"sum\": 0.07700920104980469, \"min\": 0.07700920104980469}, \"update.time\": {\"count\": 1, \"max\": 228.82390022277832, \"sum\": 228.82390022277832, \"min\": 228.82390022277832}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"state.serialize.time\": {\"count\": 1, \"max\": 0.5309581756591797, \"sum\": 0.5309581756591797, \"min\": 0.5309581756591797}, \"_shrink.time\": {\"count\": 1, \"max\": 337.0668888092041, \"sum\": 337.0668888092041, \"min\": 337.0668888092041}}, \"EndTime\": 1540897939.218556, \"Dimensions\": {\"Host\": \"algo-2\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1540897938.582035}\n",
      "\u001b[0m\n",
      "\u001b[32m[10/30/2018 11:12:19 INFO 140408755816256] Test data is not provided.\u001b[0m\n",
      "\u001b[32m[2018-10-30 11:12:19.218] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 2, \"duration\": 571, \"num_examples\": 5}\u001b[0m\n",
      "\u001b[32m[2018-10-30 11:12:19.218] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"duration\": 634, \"num_epochs\": 2, \"num_examples\": 6}\u001b[0m\n",
      "\u001b[32m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 1378.066062927246, \"sum\": 1378.066062927246, \"min\": 1378.066062927246}, \"setuptime\": {\"count\": 1, \"max\": 20.425081253051758, \"sum\": 20.425081253051758, \"min\": 20.425081253051758}}, \"EndTime\": 1540897939.223159, \"Dimensions\": {\"Host\": \"algo-2\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1540897939.218666}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-10-30 11:12:27 Completed - Training job completed\n",
      "Billable seconds: 94\n",
      "CPU times: user 8.01 s, sys: 417 ms, total: 8.43 s\n",
      "Wall time: 4min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sagemaker import KMeans\n",
    "\n",
    "data_location = 's3://{}/kmeans_highlevel_example/data'.format(bucket)\n",
    "output_location = 's3://{}/kmeans_highlevel_example/output'.format(bucket)\n",
    "\n",
    "print('training data will be uploaded to: {}'.format(data_location))\n",
    "print('training artifacts will be uploaded to: {}'.format(output_location))\n",
    "\n",
    "kmeans = KMeans(role=role, train_instance_count=2,\n",
    "                train_instance_type='ml.c4.8xlarge',\n",
    "                output_path=output_location,\n",
    "                k=10,data_location=data_location)\n",
    "\n",
    "kmeans.fit(kmeans.record_set(train_set[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using the low-level python api:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job kmeans-lowlevel-2018-10-30-11-31-19\n",
      "training artifacts will be uploaded to: s3://rh-sagemaker-20181024/kmeans_lowlevel_example/output\n",
      "InProgress\n",
      "Training job ended with status: Completed\n",
      "CPU times: user 52.3 ms, sys: 4.63 ms, total: 56.9 ms\n",
      "Wall time: 4min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "\n",
    "job_name = 'kmeans-lowlevel-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(\"Training job\", job_name)\n",
    "\n",
    "images = {\n",
    "    'us-west-2': '174872318107.dkr.ecr.us-west-2.amazonaws.com/kmeans:latest',\n",
    "    'us-east-1': '382416733822.dkr.ecr.us-east-1.amazonaws.com/kmeans:latest',\n",
    "    'us-east-2': '404615174143.dkr.ecr.us-east-2.amazonaws.com/kmeans:latest',\n",
    "    'ap-northeast-1': '351501993468.dkr.ecr.ap-northeast-1.amazonaws.com/kmeans:latest',\n",
    "    'ap-northeast-2': '835164637446.dkr.ecr.ap-northeast-2.amazonaws.com/kmeans:latest',\n",
    "    'ap-southeast-2': '712309505854.dkr.ecr.ap-southeast-2.amazonaws.com/kmeans:latest',\n",
    "    'eu-central-1': '438346466558.dkr.ecr.eu-central-1.amazonaws.com/kmeans:latest',\n",
    "    'eu-west-1': '664544806723.dkr.ecr.eu-west-1.amazonaws.com/kmeans:latest'\n",
    "}\n",
    "\n",
    "image = images[boto3.Session().region_name]\n",
    "\n",
    "data_key = 'kmeans_lowlevel_example/data'\n",
    "data_location = 's3://{}/{}'.format(bucket, data_key)\n",
    "\n",
    "output_location = 's3://{}/kmeans_lowlevel_example/output'.format(bucket)\n",
    "print('training artifacts will be uploaded to: {}'.format(output_location))\n",
    "\n",
    "create_training_params = {\n",
    "    \"AlgorithmSpecification\": {\n",
    "        \"TrainingImage\": image,\n",
    "        \"TrainingInputMode\": \"File\"\n",
    "    },\n",
    "    \"RoleArn\": role,\n",
    "    \"OutputDataConfig\": {\n",
    "        \"S3OutputPath\": output_location\n",
    "    },\n",
    "    \"ResourceConfig\": {\n",
    "        \"InstanceCount\": 2,\n",
    "        \"InstanceType\": \"ml.c4.8xlarge\",\n",
    "        \"VolumeSizeInGB\": 50\n",
    "    },\n",
    "    \"TrainingJobName\": job_name,\n",
    "    \n",
    "    \"HyperParameters\": {\n",
    "        \"k\": \"10\",\n",
    "        \"feature_dim\": \"784\",\n",
    "        \"mini_batch_size\": \"500\"\n",
    "    },\n",
    "    \"StoppingCondition\": {\n",
    "        \"MaxRuntimeInSeconds\": 60 * 60\n",
    "    },\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": data_location,\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "            \"CompressionType\": \"None\",\n",
    "            \"RecordWrapperType\": \"None\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "sagemaker = boto3.client('sagemaker')\n",
    "sagemaker.create_training_job(**create_training_params)\n",
    "\n",
    "status = sagemaker.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "print(status)\n",
    "\n",
    "try:\n",
    "    sagemaker.get_waiter('training_job_completed_or_stopped').wait(TrainingJobName=job_name)\n",
    "finally:\n",
    "    status = sagemaker.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "    print(\"Training job ended with status: \" + status)\n",
    "\n",
    "    if status == 'Failed':\n",
    "        message = sagemaker.describe_training_job(TrainingJobName=job_name)['FailureReason']\n",
    "        print('Training failed with the following error: {}'.format(message))\n",
    "\n",
    "        raise Exception('Training job failed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Deploy the Model to Amazon SageMaker\n",
    "\n",
    "2 Options\n",
    "\n",
    "* Persistent endpoint to provide one prediction at a time\n",
    "* Use batch transform to generate predictions for an entire data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 Deploy the Model to Amazon SageMaker Hosting Services\n",
    "\n",
    "3 Steps\n",
    "\n",
    "1. Create a model in SageMaker\n",
    "1. Create an endpoint configuration\n",
    "1. Create an endpoint\n",
    "\n",
    "The high level api performs all of these via a call to the `deploy` method.\n",
    "\n",
    "The low level api provides methods corresponding to each step above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## if needed, reload the previously trained model\n",
    "from sagemaker import KMeansModel\n",
    "model_data = \"s3://rh-sagemaker-20181024/kmeans_highlevel_example/output/kmeans-2018-10-30-11-08-55-639/output/model.tar.gz\"\n",
    "\n",
    "kmeans = KMeansModel(model_data=model_data, role=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: kmeans-2018-10-30-12-14-57-662\n",
      "INFO:sagemaker:Creating endpoint with name kmeans-2018-10-30-12-14-57-662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------!CPU times: user 282 ms, sys: 18.1 ms, total: 300 ms\n",
      "Wall time: 5min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## high level api\n",
    "kmeans_predictor = kmeans.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "## LOW LEVEL API\n",
    "\n",
    "## create model\n",
    "\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "\n",
    "model_name = job_name\n",
    "print(model_name)\n",
    "\n",
    "info = sagemaker.describe_training_job(TrainingJobName=job_name)\n",
    "model_data = info['ModelArtifacts']['S3ModelArtifacts']\n",
    "\n",
    "primary_container = {\n",
    "    'Image': image,\n",
    "    'ModelDataUrl': model_data\n",
    "}\n",
    "\n",
    "create_model_response = sagemaker.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = primary_container\n",
    ")\n",
    "\n",
    "print(create_model_response['ModelArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create endpoint configuration\n",
    "from time import gmtime, strftime\n",
    "\n",
    "endpoint_config_name = 'KMeansEndpointConfig-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_config_name)\n",
    "\n",
    "create_endpoint_config_response = sagemaker.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType': 'ml.m4.xlarge',\n",
    "        'InitialInstanceCount': 1,\n",
    "        'ModelName': model_name,\n",
    "        'VariantName': 'AllTraffic'\n",
    "    }]\n",
    ")\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response['EndpointConfigArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## create endpoint\n",
    "\n",
    "import time\n",
    "\n",
    "endpoint_name = 'KMeansEndpoint-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_name)\n",
    "\n",
    "create_endpoint_response = sagemaker.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "print(create_endpoint_response['EndpointArn'])\n",
    "\n",
    "resp = sagemaker.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp['EndpointStatus']\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "try:\n",
    "    sagemaker.get_waiter('endpoint_in_service').wait(EndpointName=endpoint_name)\n",
    "finally:\n",
    "    resp = sagemaker.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp['EndpointStatus']\n",
    "    print(\"Arn: \" + resp['EndpointArn'])\n",
    "    print(\"Create endpoint ended with status: \" + status)\n",
    "    \n",
    "    if status != 'InService':\n",
    "        message = sagemaker.describe_endpoint(EndpointName=endpoint_name)['FailureReason']\n",
    "        print('Create endpoint failed with the following error: {}'.format(message))\n",
    "        raise Exception('Endpoint creation did not succeed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 Deploy the Model to Amazon SageMaker Batch Transform\n",
    "\n",
    "* via console, OR\n",
    "* high level api, OR\n",
    "* low level api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## high level api:\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "import json\n",
    "\n",
    "input_key = 'kmeans_batch_example/input/valid-data.csv'\n",
    "input_location = 's3://{}/{}'.format(bucket, input_key)\n",
    "output_location = 's3://{}/kmeans_batch_example/output'.format(bucket)\n",
    "\n",
    "# convert validation set numpy array to CSV and upload to S3\n",
    "numpy.savetxt('valid-data.csv', valid_set[0], delimiter=',', fmt='%g')\n",
    "s3_client = boto3.client('s3')\n",
    "s3_client.upload_file('valid-data.csv', bucket, input_key)\n",
    "\n",
    "# initialize the transformer object\n",
    "transformer = sagemaker.transformer.Transformer(\n",
    "    base_transform_job_name='Batch-Transform',\n",
    "    model_name=model_name,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.c4.xlarge',\n",
    "    output_path=output_location\n",
    ")\n",
    "\n",
    "# start a transform job\n",
    "transformer.transform(input_location, content_type='text/csv', split_type='Line')\n",
    "\n",
    "# wait for the job to complete\n",
    "transformer.wait()\n",
    "\n",
    "# fetch the validation result\n",
    "s3_client.download_file(bucket, 'kmeans_batch_example/output/valid-data.csv.out', 'valid-result')\n",
    "\n",
    "with open('valid-result') as f:\n",
    "    results = f.readlines()\n",
    "    \n",
    "print(\"Sample transform result: {}\".format(results[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## low level api\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "import json\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "from time import gmtime, strftime\n",
    "\n",
    "batch_job_name = 'Batch-Transform-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "input_location = 's3://{}/kmeans_batch_example/input'.format(bucket)\n",
    "output_location = 's3://{}/kmeans_batch_example/output'.format(bucket)\n",
    "\n",
    "# convert the validation set numpy array to a csv file and upload to S3\n",
    "numpy.savetxt('valid-data.csv', valid_set[0], delimiter=',', fmt='%g')\n",
    "s3_client = boto3.client('s3')\n",
    "input_key = \"{}/valid_data.csv\".format(urlparse(input_location).path.lstrip('/'))\n",
    "s3_client.upload_file('valid-data.csv', bucket, input_key)\n",
    "\n",
    "# create a transform job\n",
    "sm = boto3.client('sagemaker')\n",
    "request = {\n",
    "    \"TransformJobName\": batch_job_name,\n",
    "    \"ModelName\": model_name,\n",
    "    \"MaxConcurrentTransforms\": 4,\n",
    "    \"MaxPayloadInMB\": 6,\n",
    "    \"BatchStrategy\": \"MultiRecord\",\n",
    "    \"TransformOutput\": {\n",
    "        \"S3OutputPath\": output_location\n",
    "    },\n",
    "    \"TransformInput\": {\n",
    "        \"DataSource\": {\n",
    "            \"S3DataSource\": {\n",
    "                \"S3DataType\": \"S3Prefix\",\n",
    "                \n",
    "                \"S3Uri\": input_location \n",
    "            }\n",
    "        },\n",
    "        \"ContentType\": \"text/csv\",\n",
    "        \"SplitType\": \"Line\",\n",
    "        \"CompressionType\": \"None\"\n",
    "    },\n",
    "    \"TransformResources\": {\n",
    "        \"InstanceType\": \"ml.m4.xlarge\",\n",
    "        \"InstanceCount\": 1\n",
    "    }\n",
    "}\n",
    "\n",
    "sm.create_transform_job(**request)\n",
    "print(\"Created Transform job with name: \", batch_job_name)\n",
    "\n",
    "### Wait until job completion\n",
    "while(True):\n",
    "    response = sm.describe_transform_job(TransformJobName=batch_job_name)\n",
    "    status = response['TransformJobStatus']\n",
    "    if  status == 'Completed':\n",
    "        print(\"Transform job ended with status: \" + status)\n",
    "        break\n",
    "    if status == 'Failed':\n",
    "        message = response['FailureReason']\n",
    "        print('Transform failed with the following error: {}'.format(message))\n",
    "        raise Exception('Transform job failed') \n",
    "    print(\"Transform job is still in status: \" + status)    \n",
    "    time.sleep(30)\n",
    "    \n",
    "### Fetch transform output\n",
    "output_key = \"{}/valid_data.csv.out\".format(urlparse(output_location).path.lstrip('/'))\n",
    "s3_client.download_file(bucket, output_key, 'valid-result')\n",
    "with open('valid-result') as f:\n",
    "    results = f.readlines()   \n",
    "    print(\"Sample transform result: {}\".format(results[0]))\n",
    "\n",
    "## view details of transform job\n",
    "response = sm.describe_transform_jbo(TransformJobName=job_name)\n",
    "\n",
    "## list transform jobs\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "request = {\n",
    "    \"StatusEquals\": \"Completed\",\n",
    "    \"SortBy\": \"CreationTime\",\n",
    "    \"SortOrder\": \"Descending\",\n",
    "    \"MaxResults\": 20,\n",
    "}\n",
    "\n",
    "response = sm.list_transform_jobs(**request)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
